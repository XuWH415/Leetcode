Design and implement a data structure for Least Recently Used (LRU) cache. It should support the following operations: get and put.

get(key) - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.
put(key, value) - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.

Follow up:
Could you do both operations in O(1) time complexity?

Example:

LRUCache cache = new LRUCache( 2 /* capacity */ );

cache.put(1, 1);
cache.put(2, 2);
cache.get(1);       // returns 1
cache.put(3, 3);    // evicts key 2
cache.get(2);       // returns -1 (not found)
cache.put(4, 4);    // evicts key 1
cache.get(1);       // returns -1 (not found)
cache.get(3);       // returns 3
cache.get(4);       // returns 4

Tags: Design
Similar Problems: (H) LFU Cache



----------------------------------------------------------------------------------------------------------------------------------------



*** Python ***

### Dictionary and Double Linked List: T = O(1) for put() and get()
class ListNode():
    def __init__(self, key, val):
        self.key = key
        self.val = val
        self.before = None
        self.next = None
        
class LRUCache(object):
    def __init__(self, capacity):
        """
        :type capacity: int
        """
        self.capacity = capacity
        self.size = 0
        self.d = dict()
        self.head = ListNode(-1, -1)
        self.tail = ListNode(-2, -2)
        self.head.next = self.tail
        self.tail.before = self.head

    def get(self, key):
        """
        :type key: int
        :rtype: int
        """
        if key in self.d:
            self.moveToTop(key)
            return self.d[key].val
        else:
            return -1
    
    def put(self, key, value):
        """
        :type key: int
        :type value: int
        :rtype: void
        """
        if key in self.d:
            self.d[key].val = value
            self.moveToTop(key)
        else:
            if self.size >= self.capacity:
                p = self.tail.before
                self.deleteNode(p.key)
                del self.d[p.key]
            self.d[key] = ListNode(key, value)
            self.insertNodeToTop(key)
            self.size += 1
        return self.d[key].val
    
    def moveToTop(self, key):
        self.deleteNode(key)
        self.insertNodeToTop(key)
        
    def deleteNode(self, key):
        self.d[key].before.next = self.d[key].next
        self.d[key].next.before = self.d[key].before
        self.d[key].before = self.d[key].next = None
        
    def insertNodeToTop(self, key):
        if key in self.d and not self.d[key].before and not self.d[key].next:
            self.d[key].next = self.head.next
            self.d[key].before = self.head
            self.head.next.before = self.d[key]
            self.head.next = self.d[key]
# Your LRUCache object will be instantiated and called as such:
# obj = LRUCache(capacity)
# param_1 = obj.get(key)
# obj.put(key,value)
